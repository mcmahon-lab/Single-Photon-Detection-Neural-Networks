{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "scriptPath = Path(sys.path[0])\n",
    "parentPath = scriptPath.parent\n",
    "dataPath = parentPath / 'data'\n",
    "srcPath = parentPath / 'src'\n",
    "modelPath = parentPath / 'models'\n",
    "plotPath = parentPath / 'plots'\n",
    "miscPath = parentPath / 'misc'\n",
    "\n",
    "sys.path.append(srcPath.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size = 128\n",
    "image_size = 28\n",
    "\n",
    "\"\"\" Prepare data loaders \"\"\"\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(dataPath, train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize(image_size),\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(dataPath, train=False, transform=transforms.Compose([\n",
    "                       transforms.Resize(image_size),\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Training procedure\n",
    "def train(epoch):\n",
    "\n",
    "    slope = 1.\n",
    "\n",
    "    print('\\n# Epoch : {} - Slope : {}'.format(epoch, slope))\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss = train_loss.item()\n",
    "    train_acc = correct / len(train_loader.dataset)\n",
    "\n",
    "    print(f'Training Loss : {train_loss}, training accuracy : {int(correct)}/{len(train_loader.dataset)} ({train_acc*100:.3f}%)')\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "# Testing procedure\n",
    "def test(epoch, best_acc):\n",
    "    slope = 1.\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0.0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target).data.item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = correct / len(test_loader.dataset)\n",
    "    print(f'Test set: average loss: {test_loss:.4f}, accuracy: {int(correct)}/{len(test_loader.dataset)} ({100. * test_acc:.3f}%)')\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST28x28_conv[16]_ks[5]_s[1]_N400_batch128_SGD_lr0.01_mom0.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PDConvNet(\n",
       "  (convs): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "    (1): PhotonActivationCoh(\n",
       "      (act): PhotonCountingP()\n",
       "    )\n",
       "    (2): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
       "  )\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=3136, out_features=400, bias=False)\n",
       "  (linear_act): PhotonActivationCoh(\n",
       "    (act): PhotonCountingP()\n",
       "  )\n",
       "  (fc2): Linear(in_features=400, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SPDNN_Conv import PDConvNet\n",
    "\n",
    "n_linear = 400\n",
    "n_chan = [16]\n",
    "stride = [1]\n",
    "kernel_size = [5]\n",
    "anneal_factor = 1.000\n",
    "\n",
    "model = PDConvNet(d_input=(1,image_size,image_size),n_linear=n_linear,n_output=10,\\\n",
    "                  n_chan=n_chan,kss=kernel_size,ss=stride,batchnorm=False).to(device)\n",
    "\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "num_epoch = 300\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=lr, momentum=momentum)\n",
    "\n",
    "model_name = f\"MNIST{image_size}x{image_size}_conv{n_chan}_ks{kernel_size}_s{stride}_N{n_linear}_batch{batch_size}_SGD_lr{lr}_mom{momentum}\"\n",
    "\n",
    "acc_track = []\n",
    "train_acc_track = []\n",
    "best_acc = 0.\n",
    "print(model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch : 1 - Slope : 1.0\n",
      "Training Loss : 0.9554390907287598, training accuracy : 41647/60000 (69.412%)\n",
      "Test set: average loss: 0.0022, accuracy: 9148/10000 (91.480%)\n",
      "Best test accuracy so far: 91.480%\n",
      "# Epoch : 2 - Slope : 1.0\n",
      "Training Loss : 0.22356373071670532, training accuracy : 55948/60000 (93.247%)\n",
      "Test set: average loss: 0.0013, accuracy: 9517/10000 (95.170%)\n",
      "Best test accuracy so far: 95.170%\n",
      "# Epoch : 3 - Slope : 1.0\n",
      "Training Loss : 0.14806203544139862, training accuracy : 57280/60000 (95.467%)\n",
      "Test set: average loss: 0.0010, accuracy: 9612/10000 (96.120%)\n",
      "Best test accuracy so far: 96.120%\n",
      "# Epoch : 4 - Slope : 1.0\n",
      "Training Loss : 0.11315246671438217, training accuracy : 57929/60000 (96.548%)\n",
      "Test set: average loss: 0.0008, accuracy: 9701/10000 (97.010%)\n",
      "Best test accuracy so far: 97.010%\n",
      "# Epoch : 5 - Slope : 1.0\n",
      "Training Loss : 0.09302394092082977, training accuracy : 58259/60000 (97.098%)\n",
      "Test set: average loss: 0.0008, accuracy: 9697/10000 (96.970%)\n",
      "Best test accuracy so far: 97.010%\n",
      "# Epoch : 6 - Slope : 1.0\n",
      "Training Loss : 0.08180637657642365, training accuracy : 58494/60000 (97.490%)\n",
      "Test set: average loss: 0.0006, accuracy: 9772/10000 (97.720%)\n",
      "Best test accuracy so far: 97.720%\n",
      "# Epoch : 7 - Slope : 1.0\n",
      "Training Loss : 0.07253634184598923, training accuracy : 58676/60000 (97.793%)\n",
      "Test set: average loss: 0.0006, accuracy: 9781/10000 (97.810%)\n",
      "Best test accuracy so far: 97.810%\n",
      "# Epoch : 8 - Slope : 1.0\n",
      "Training Loss : 0.06490349024534225, training accuracy : 58791/60000 (97.985%)\n",
      "Test set: average loss: 0.0005, accuracy: 9798/10000 (97.980%)\n",
      "Best test accuracy so far: 97.980%\n",
      "# Epoch : 9 - Slope : 1.0\n",
      "Training Loss : 0.05739045515656471, training accuracy : 58966/60000 (98.277%)\n",
      "Test set: average loss: 0.0005, accuracy: 9801/10000 (98.010%)\n",
      "Best test accuracy so far: 98.010%\n",
      "# Epoch : 10 - Slope : 1.0\n",
      "Training Loss : 0.052808672189712524, training accuracy : 59053/60000 (98.422%)\n",
      "Test set: average loss: 0.0004, accuracy: 9815/10000 (98.150%)\n",
      "Best test accuracy so far: 98.150%\n",
      "# Epoch : 11 - Slope : 1.0\n",
      "Training Loss : 0.04866977035999298, training accuracy : 59095/60000 (98.492%)\n",
      "Test set: average loss: 0.0004, accuracy: 9830/10000 (98.300%)\n",
      "Best test accuracy so far: 98.300%\n",
      "# Epoch : 12 - Slope : 1.0\n",
      "Training Loss : 0.0462605245411396, training accuracy : 59126/60000 (98.543%)\n",
      "Test set: average loss: 0.0004, accuracy: 9817/10000 (98.170%)\n",
      "Best test accuracy so far: 98.300%\n",
      "# Epoch : 13 - Slope : 1.0\n",
      "Training Loss : 0.04392767325043678, training accuracy : 59181/60000 (98.635%)\n",
      "Test set: average loss: 0.0004, accuracy: 9821/10000 (98.210%)\n",
      "Best test accuracy so far: 98.300%\n",
      "# Epoch : 14 - Slope : 1.0\n",
      "Training Loss : 0.04032067209482193, training accuracy : 59256/60000 (98.760%)\n",
      "Test set: average loss: 0.0004, accuracy: 9835/10000 (98.350%)\n",
      "Best test accuracy so far: 98.350%\n",
      "# Epoch : 15 - Slope : 1.0\n",
      "Training Loss : 0.037752121686935425, training accuracy : 59305/60000 (98.842%)\n",
      "Test set: average loss: 0.0004, accuracy: 9833/10000 (98.330%)\n",
      "Best test accuracy so far: 98.350%\n",
      "# Epoch : 16 - Slope : 1.0\n",
      "Training Loss : 0.035786908119916916, training accuracy : 59336/60000 (98.893%)\n",
      "Test set: average loss: 0.0004, accuracy: 9841/10000 (98.410%)\n",
      "Best test accuracy so far: 98.410%\n",
      "# Epoch : 17 - Slope : 1.0\n",
      "Training Loss : 0.03399765118956566, training accuracy : 59369/60000 (98.948%)\n",
      "Test set: average loss: 0.0004, accuracy: 9846/10000 (98.460%)\n",
      "Best test accuracy so far: 98.460%\n",
      "# Epoch : 18 - Slope : 1.0\n",
      "Training Loss : 0.03372223302721977, training accuracy : 59347/60000 (98.912%)\n",
      "Test set: average loss: 0.0004, accuracy: 9854/10000 (98.540%)\n",
      "Best test accuracy so far: 98.540%\n",
      "# Epoch : 19 - Slope : 1.0\n",
      "Training Loss : 0.031089337542653084, training accuracy : 59427/60000 (99.045%)\n",
      "Test set: average loss: 0.0004, accuracy: 9861/10000 (98.610%)\n",
      "Best test accuracy so far: 98.610%\n",
      "# Epoch : 20 - Slope : 1.0\n",
      "Training Loss : 0.030127806589007378, training accuracy : 59442/60000 (99.070%)\n",
      "Test set: average loss: 0.0003, accuracy: 9859/10000 (98.590%)\n",
      "Best test accuracy so far: 98.610%\n",
      "# Epoch : 21 - Slope : 1.0\n",
      "Training Loss : 0.028169283643364906, training accuracy : 59456/60000 (99.093%)\n",
      "Test set: average loss: 0.0004, accuracy: 9846/10000 (98.460%)\n",
      "Best test accuracy so far: 98.610%\n",
      "# Epoch : 22 - Slope : 1.0\n",
      "Training Loss : 0.026982497423887253, training accuracy : 59500/60000 (99.167%)\n",
      "Test set: average loss: 0.0003, accuracy: 9866/10000 (98.660%)\n",
      "Best test accuracy so far: 98.660%\n",
      "# Epoch : 23 - Slope : 1.0\n",
      "Training Loss : 0.02660815790295601, training accuracy : 59503/60000 (99.172%)\n",
      "Test set: average loss: 0.0003, accuracy: 9853/10000 (98.530%)\n",
      "Best test accuracy so far: 98.660%\n",
      "# Epoch : 24 - Slope : 1.0\n",
      "Training Loss : 0.024330593645572662, training accuracy : 59554/60000 (99.257%)\n",
      "Test set: average loss: 0.0003, accuracy: 9847/10000 (98.470%)\n",
      "Best test accuracy so far: 98.660%\n",
      "# Epoch : 25 - Slope : 1.0\n",
      "Training Loss : 0.02414069138467312, training accuracy : 59541/60000 (99.235%)\n",
      "Test set: average loss: 0.0004, accuracy: 9836/10000 (98.360%)\n",
      "Best test accuracy so far: 98.660%\n",
      "# Epoch : 26 - Slope : 1.0\n",
      "Training Loss : 0.023329278454184532, training accuracy : 59565/60000 (99.275%)\n",
      "Test set: average loss: 0.0003, accuracy: 9862/10000 (98.620%)\n",
      "Best test accuracy so far: 98.660%\n",
      "# Epoch : 27 - Slope : 1.0\n",
      "Training Loss : 0.023427870124578476, training accuracy : 59540/60000 (99.233%)\n",
      "Test set: average loss: 0.0003, accuracy: 9876/10000 (98.760%)\n",
      "Best test accuracy so far: 98.760%\n",
      "# Epoch : 28 - Slope : 1.0\n",
      "Training Loss : 0.021585563197731972, training accuracy : 59576/60000 (99.293%)\n",
      "Test set: average loss: 0.0003, accuracy: 9854/10000 (98.540%)\n",
      "Best test accuracy so far: 98.760%\n",
      "# Epoch : 29 - Slope : 1.0\n",
      "Training Loss : 0.021073129028081894, training accuracy : 59601/60000 (99.335%)\n",
      "Test set: average loss: 0.0003, accuracy: 9851/10000 (98.510%)\n",
      "Best test accuracy so far: 98.760%\n",
      "# Epoch : 30 - Slope : 1.0\n",
      "Training Loss : 0.019143899902701378, training accuracy : 59657/60000 (99.428%)\n",
      "Test set: average loss: 0.0003, accuracy: 9849/10000 (98.490%)\n",
      "Best test accuracy so far: 98.760%\n",
      "# Epoch : 31 - Slope : 1.0\n",
      "Training Loss : 0.01849658042192459, training accuracy : 59669/60000 (99.448%)\n",
      "Test set: average loss: 0.0003, accuracy: 9869/10000 (98.690%)\n",
      "Best test accuracy so far: 98.760%\n",
      "# Epoch : 32 - Slope : 1.0\n",
      "Training Loss : 0.01901204325258732, training accuracy : 59636/60000 (99.393%)\n",
      "Test set: average loss: 0.0003, accuracy: 9860/10000 (98.600%)\n",
      "Best test accuracy so far: 98.760%\n",
      "# Epoch : 33 - Slope : 1.0\n",
      "Training Loss : 0.017572592943906784, training accuracy : 59682/60000 (99.470%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 98.860%\n",
      "# Epoch : 34 - Slope : 1.0\n",
      "Training Loss : 0.0174141526222229, training accuracy : 59680/60000 (99.467%)\n",
      "Test set: average loss: 0.0003, accuracy: 9860/10000 (98.600%)\n",
      "Best test accuracy so far: 98.860%\n",
      "# Epoch : 35 - Slope : 1.0\n",
      "Training Loss : 0.016298435628414154, training accuracy : 59715/60000 (99.525%)\n",
      "Test set: average loss: 0.0003, accuracy: 9856/10000 (98.560%)\n",
      "Best test accuracy so far: 98.860%\n",
      "# Epoch : 36 - Slope : 1.0\n",
      "Training Loss : 0.016700349748134613, training accuracy : 59712/60000 (99.520%)\n",
      "Test set: average loss: 0.0003, accuracy: 9872/10000 (98.720%)\n",
      "Best test accuracy so far: 98.860%\n",
      "# Epoch : 37 - Slope : 1.0\n",
      "Training Loss : 0.014531326480209827, training accuracy : 59743/60000 (99.572%)\n",
      "Test set: average loss: 0.0003, accuracy: 9876/10000 (98.760%)\n",
      "Best test accuracy so far: 98.860%\n",
      "# Epoch : 38 - Slope : 1.0\n",
      "Training Loss : 0.01438642106950283, training accuracy : 59743/60000 (99.572%)\n",
      "Test set: average loss: 0.0003, accuracy: 9869/10000 (98.690%)\n",
      "Best test accuracy so far: 98.860%\n",
      "# Epoch : 39 - Slope : 1.0\n",
      "Training Loss : 0.015399581752717495, training accuracy : 59712/60000 (99.520%)\n",
      "Test set: average loss: 0.0003, accuracy: 9868/10000 (98.680%)\n",
      "Best test accuracy so far: 98.860%\n",
      "# Epoch : 40 - Slope : 1.0\n",
      "Training Loss : 0.014109962619841099, training accuracy : 59740/60000 (99.567%)\n",
      "Test set: average loss: 0.0003, accuracy: 9867/10000 (98.670%)\n",
      "Best test accuracy so far: 98.860%\n",
      "# Epoch : 41 - Slope : 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.013712727464735508, training accuracy : 59750/60000 (99.583%)\n",
      "Test set: average loss: 0.0003, accuracy: 9862/10000 (98.620%)\n",
      "Best test accuracy so far: 98.860%\n",
      "# Epoch : 42 - Slope : 1.0\n",
      "Training Loss : 0.013551495969295502, training accuracy : 59748/60000 (99.580%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 43 - Slope : 1.0\n",
      "Training Loss : 0.01333883311599493, training accuracy : 59754/60000 (99.590%)\n",
      "Test set: average loss: 0.0003, accuracy: 9864/10000 (98.640%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 44 - Slope : 1.0\n",
      "Training Loss : 0.012342890724539757, training accuracy : 59774/60000 (99.623%)\n",
      "Test set: average loss: 0.0003, accuracy: 9862/10000 (98.620%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 45 - Slope : 1.0\n",
      "Training Loss : 0.011940838769078255, training accuracy : 59774/60000 (99.623%)\n",
      "Test set: average loss: 0.0003, accuracy: 9870/10000 (98.700%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 46 - Slope : 1.0\n",
      "Training Loss : 0.012274954468011856, training accuracy : 59793/60000 (99.655%)\n",
      "Test set: average loss: 0.0003, accuracy: 9878/10000 (98.780%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 47 - Slope : 1.0\n",
      "Training Loss : 0.012410582974553108, training accuracy : 59759/60000 (99.598%)\n",
      "Test set: average loss: 0.0003, accuracy: 9881/10000 (98.810%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 48 - Slope : 1.0\n",
      "Training Loss : 0.01184915378689766, training accuracy : 59798/60000 (99.663%)\n",
      "Test set: average loss: 0.0003, accuracy: 9876/10000 (98.760%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 49 - Slope : 1.0\n",
      "Training Loss : 0.011665316298604012, training accuracy : 59777/60000 (99.628%)\n",
      "Test set: average loss: 0.0003, accuracy: 9871/10000 (98.710%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 50 - Slope : 1.0\n",
      "Training Loss : 0.011467968113720417, training accuracy : 59789/60000 (99.648%)\n",
      "Test set: average loss: 0.0003, accuracy: 9882/10000 (98.820%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 51 - Slope : 1.0\n",
      "Training Loss : 0.010793570429086685, training accuracy : 59804/60000 (99.673%)\n",
      "Test set: average loss: 0.0003, accuracy: 9884/10000 (98.840%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 52 - Slope : 1.0\n",
      "Training Loss : 0.01010217983275652, training accuracy : 59816/60000 (99.693%)\n",
      "Test set: average loss: 0.0003, accuracy: 9867/10000 (98.670%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 53 - Slope : 1.0\n",
      "Training Loss : 0.010019787587225437, training accuracy : 59827/60000 (99.712%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 54 - Slope : 1.0\n",
      "Training Loss : 0.009965701960027218, training accuracy : 59826/60000 (99.710%)\n",
      "Test set: average loss: 0.0003, accuracy: 9866/10000 (98.660%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 55 - Slope : 1.0\n",
      "Training Loss : 0.009789655916392803, training accuracy : 59833/60000 (99.722%)\n",
      "Test set: average loss: 0.0003, accuracy: 9872/10000 (98.720%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 56 - Slope : 1.0\n",
      "Training Loss : 0.010067394934594631, training accuracy : 59827/60000 (99.712%)\n",
      "Test set: average loss: 0.0003, accuracy: 9878/10000 (98.780%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 57 - Slope : 1.0\n",
      "Training Loss : 0.009944448247551918, training accuracy : 59819/60000 (99.698%)\n",
      "Test set: average loss: 0.0003, accuracy: 9869/10000 (98.690%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 58 - Slope : 1.0\n",
      "Training Loss : 0.009355372749269009, training accuracy : 59836/60000 (99.727%)\n",
      "Test set: average loss: 0.0003, accuracy: 9881/10000 (98.810%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 59 - Slope : 1.0\n",
      "Training Loss : 0.008410723879933357, training accuracy : 59859/60000 (99.765%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 60 - Slope : 1.0\n",
      "Training Loss : 0.008624326437711716, training accuracy : 59853/60000 (99.755%)\n",
      "Test set: average loss: 0.0003, accuracy: 9878/10000 (98.780%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 61 - Slope : 1.0\n",
      "Training Loss : 0.0084487060084939, training accuracy : 59847/60000 (99.745%)\n",
      "Test set: average loss: 0.0003, accuracy: 9883/10000 (98.830%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 62 - Slope : 1.0\n",
      "Training Loss : 0.00814647413790226, training accuracy : 59860/60000 (99.767%)\n",
      "Test set: average loss: 0.0003, accuracy: 9877/10000 (98.770%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 63 - Slope : 1.0\n",
      "Training Loss : 0.008372818119823933, training accuracy : 59853/60000 (99.755%)\n",
      "Test set: average loss: 0.0003, accuracy: 9877/10000 (98.770%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 64 - Slope : 1.0\n",
      "Training Loss : 0.008727540262043476, training accuracy : 59848/60000 (99.747%)\n",
      "Test set: average loss: 0.0003, accuracy: 9871/10000 (98.710%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 65 - Slope : 1.0\n",
      "Training Loss : 0.008258688263595104, training accuracy : 59848/60000 (99.747%)\n",
      "Test set: average loss: 0.0003, accuracy: 9877/10000 (98.770%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 66 - Slope : 1.0\n",
      "Training Loss : 0.007960726507008076, training accuracy : 59868/60000 (99.780%)\n",
      "Test set: average loss: 0.0003, accuracy: 9865/10000 (98.650%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 67 - Slope : 1.0\n",
      "Training Loss : 0.007745825685560703, training accuracy : 59869/60000 (99.782%)\n",
      "Test set: average loss: 0.0003, accuracy: 9879/10000 (98.790%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 68 - Slope : 1.0\n",
      "Training Loss : 0.006780439522117376, training accuracy : 59882/60000 (99.803%)\n",
      "Test set: average loss: 0.0003, accuracy: 9881/10000 (98.810%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 69 - Slope : 1.0\n",
      "Training Loss : 0.007225572597235441, training accuracy : 59870/60000 (99.783%)\n",
      "Test set: average loss: 0.0003, accuracy: 9881/10000 (98.810%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 70 - Slope : 1.0\n",
      "Training Loss : 0.007217976730316877, training accuracy : 59877/60000 (99.795%)\n",
      "Test set: average loss: 0.0003, accuracy: 9885/10000 (98.850%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 71 - Slope : 1.0\n",
      "Training Loss : 0.0069497982040047646, training accuracy : 59884/60000 (99.807%)\n",
      "Test set: average loss: 0.0003, accuracy: 9885/10000 (98.850%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 72 - Slope : 1.0\n",
      "Training Loss : 0.006754775065928698, training accuracy : 59888/60000 (99.813%)\n",
      "Test set: average loss: 0.0003, accuracy: 9872/10000 (98.720%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 73 - Slope : 1.0\n",
      "Training Loss : 0.00670846551656723, training accuracy : 59881/60000 (99.802%)\n",
      "Test set: average loss: 0.0003, accuracy: 9877/10000 (98.770%)\n",
      "Best test accuracy so far: 98.880%\n",
      "# Epoch : 74 - Slope : 1.0\n",
      "Training Loss : 0.006547057535499334, training accuracy : 59894/60000 (99.823%)\n",
      "Test set: average loss: 0.0003, accuracy: 9904/10000 (99.040%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 75 - Slope : 1.0\n",
      "Training Loss : 0.00647008465602994, training accuracy : 59895/60000 (99.825%)\n",
      "Test set: average loss: 0.0003, accuracy: 9884/10000 (98.840%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 76 - Slope : 1.0\n",
      "Training Loss : 0.0068426188081502914, training accuracy : 59888/60000 (99.813%)\n",
      "Test set: average loss: 0.0003, accuracy: 9881/10000 (98.810%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 77 - Slope : 1.0\n",
      "Training Loss : 0.00627093855291605, training accuracy : 59894/60000 (99.823%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 78 - Slope : 1.0\n",
      "Training Loss : 0.006130038294941187, training accuracy : 59906/60000 (99.843%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 79 - Slope : 1.0\n",
      "Training Loss : 0.006120036821812391, training accuracy : 59901/60000 (99.835%)\n",
      "Test set: average loss: 0.0003, accuracy: 9876/10000 (98.760%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 80 - Slope : 1.0\n",
      "Training Loss : 0.0059639583341777325, training accuracy : 59903/60000 (99.838%)\n",
      "Test set: average loss: 0.0003, accuracy: 9867/10000 (98.670%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 81 - Slope : 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.006618469022214413, training accuracy : 59878/60000 (99.797%)\n",
      "Test set: average loss: 0.0003, accuracy: 9884/10000 (98.840%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 82 - Slope : 1.0\n",
      "Training Loss : 0.006136548239737749, training accuracy : 59903/60000 (99.838%)\n",
      "Test set: average loss: 0.0003, accuracy: 9889/10000 (98.890%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 83 - Slope : 1.0\n",
      "Training Loss : 0.006174628157168627, training accuracy : 59900/60000 (99.833%)\n",
      "Test set: average loss: 0.0003, accuracy: 9887/10000 (98.870%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 84 - Slope : 1.0\n",
      "Training Loss : 0.006086935754865408, training accuracy : 59890/60000 (99.817%)\n",
      "Test set: average loss: 0.0003, accuracy: 9887/10000 (98.870%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 85 - Slope : 1.0\n",
      "Training Loss : 0.005476600024849176, training accuracy : 59918/60000 (99.863%)\n",
      "Test set: average loss: 0.0003, accuracy: 9894/10000 (98.940%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 86 - Slope : 1.0\n",
      "Training Loss : 0.0058442032895982265, training accuracy : 59902/60000 (99.837%)\n",
      "Test set: average loss: 0.0003, accuracy: 9885/10000 (98.850%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 87 - Slope : 1.0\n",
      "Training Loss : 0.005397483240813017, training accuracy : 59911/60000 (99.852%)\n",
      "Test set: average loss: 0.0003, accuracy: 9878/10000 (98.780%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 88 - Slope : 1.0\n",
      "Training Loss : 0.005711256060749292, training accuracy : 59909/60000 (99.848%)\n",
      "Test set: average loss: 0.0003, accuracy: 9876/10000 (98.760%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 89 - Slope : 1.0\n",
      "Training Loss : 0.005733525846153498, training accuracy : 59907/60000 (99.845%)\n",
      "Test set: average loss: 0.0003, accuracy: 9882/10000 (98.820%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 90 - Slope : 1.0\n",
      "Training Loss : 0.0052374075166881084, training accuracy : 59911/60000 (99.852%)\n",
      "Test set: average loss: 0.0003, accuracy: 9893/10000 (98.930%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 91 - Slope : 1.0\n",
      "Training Loss : 0.004716288764029741, training accuracy : 59926/60000 (99.877%)\n",
      "Test set: average loss: 0.0003, accuracy: 9874/10000 (98.740%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 92 - Slope : 1.0\n",
      "Training Loss : 0.004728593863546848, training accuracy : 59914/60000 (99.857%)\n",
      "Test set: average loss: 0.0003, accuracy: 9890/10000 (98.900%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 93 - Slope : 1.0\n",
      "Training Loss : 0.004795741755515337, training accuracy : 59919/60000 (99.865%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 94 - Slope : 1.0\n",
      "Training Loss : 0.0046492996625602245, training accuracy : 59938/60000 (99.897%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 95 - Slope : 1.0\n",
      "Training Loss : 0.004062197171151638, training accuracy : 59947/60000 (99.912%)\n",
      "Test set: average loss: 0.0003, accuracy: 9881/10000 (98.810%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 96 - Slope : 1.0\n",
      "Training Loss : 0.004419566597789526, training accuracy : 59933/60000 (99.888%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 97 - Slope : 1.0\n",
      "Training Loss : 0.005498339422047138, training accuracy : 59907/60000 (99.845%)\n",
      "Test set: average loss: 0.0003, accuracy: 9887/10000 (98.870%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 98 - Slope : 1.0\n",
      "Training Loss : 0.004927447065711021, training accuracy : 59924/60000 (99.873%)\n",
      "Test set: average loss: 0.0004, accuracy: 9878/10000 (98.780%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 99 - Slope : 1.0\n",
      "Training Loss : 0.004516982939094305, training accuracy : 59926/60000 (99.877%)\n",
      "Test set: average loss: 0.0003, accuracy: 9885/10000 (98.850%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 100 - Slope : 1.0\n",
      "Training Loss : 0.004579136148095131, training accuracy : 59919/60000 (99.865%)\n",
      "Test set: average loss: 0.0003, accuracy: 9890/10000 (98.900%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 101 - Slope : 1.0\n",
      "Training Loss : 0.004651380702853203, training accuracy : 59922/60000 (99.870%)\n",
      "Test set: average loss: 0.0003, accuracy: 9884/10000 (98.840%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 102 - Slope : 1.0\n",
      "Training Loss : 0.004528189543634653, training accuracy : 59928/60000 (99.880%)\n",
      "Test set: average loss: 0.0003, accuracy: 9876/10000 (98.760%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 103 - Slope : 1.0\n",
      "Training Loss : 0.004625346511602402, training accuracy : 59926/60000 (99.877%)\n",
      "Test set: average loss: 0.0003, accuracy: 9880/10000 (98.800%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 104 - Slope : 1.0\n",
      "Training Loss : 0.004319386091083288, training accuracy : 59928/60000 (99.880%)\n",
      "Test set: average loss: 0.0003, accuracy: 9871/10000 (98.710%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 105 - Slope : 1.0\n",
      "Training Loss : 0.0037623790558427572, training accuracy : 59947/60000 (99.912%)\n",
      "Test set: average loss: 0.0003, accuracy: 9883/10000 (98.830%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 106 - Slope : 1.0\n",
      "Training Loss : 0.004309529438614845, training accuracy : 59931/60000 (99.885%)\n",
      "Test set: average loss: 0.0003, accuracy: 9871/10000 (98.710%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 107 - Slope : 1.0\n",
      "Training Loss : 0.004382722545415163, training accuracy : 59932/60000 (99.887%)\n",
      "Test set: average loss: 0.0003, accuracy: 9883/10000 (98.830%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 108 - Slope : 1.0\n",
      "Training Loss : 0.004552069585770369, training accuracy : 59924/60000 (99.873%)\n",
      "Test set: average loss: 0.0003, accuracy: 9889/10000 (98.890%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 109 - Slope : 1.0\n",
      "Training Loss : 0.004126059822738171, training accuracy : 59927/60000 (99.878%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 110 - Slope : 1.0\n",
      "Training Loss : 0.003841722384095192, training accuracy : 59939/60000 (99.898%)\n",
      "Test set: average loss: 0.0003, accuracy: 9894/10000 (98.940%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 111 - Slope : 1.0\n",
      "Training Loss : 0.003788903821259737, training accuracy : 59947/60000 (99.912%)\n",
      "Test set: average loss: 0.0003, accuracy: 9882/10000 (98.820%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 112 - Slope : 1.0\n",
      "Training Loss : 0.003550303867086768, training accuracy : 59952/60000 (99.920%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 113 - Slope : 1.0\n",
      "Training Loss : 0.003906632773578167, training accuracy : 59935/60000 (99.892%)\n",
      "Test set: average loss: 0.0003, accuracy: 9887/10000 (98.870%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 114 - Slope : 1.0\n",
      "Training Loss : 0.004208394791930914, training accuracy : 59934/60000 (99.890%)\n",
      "Test set: average loss: 0.0003, accuracy: 9899/10000 (98.990%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 115 - Slope : 1.0\n",
      "Training Loss : 0.003960275091230869, training accuracy : 59938/60000 (99.897%)\n",
      "Test set: average loss: 0.0003, accuracy: 9883/10000 (98.830%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 116 - Slope : 1.0\n",
      "Training Loss : 0.0036859812680631876, training accuracy : 59948/60000 (99.913%)\n",
      "Test set: average loss: 0.0003, accuracy: 9878/10000 (98.780%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 117 - Slope : 1.0\n",
      "Training Loss : 0.0034864123445004225, training accuracy : 59948/60000 (99.913%)\n",
      "Test set: average loss: 0.0003, accuracy: 9882/10000 (98.820%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 118 - Slope : 1.0\n",
      "Training Loss : 0.0036733115557581186, training accuracy : 59938/60000 (99.897%)\n",
      "Test set: average loss: 0.0003, accuracy: 9901/10000 (99.010%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 119 - Slope : 1.0\n",
      "Training Loss : 0.004110727459192276, training accuracy : 59929/60000 (99.882%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 120 - Slope : 1.0\n",
      "Training Loss : 0.003908251877874136, training accuracy : 59939/60000 (99.898%)\n",
      "Test set: average loss: 0.0003, accuracy: 9894/10000 (98.940%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 121 - Slope : 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.00299362326040864, training accuracy : 59953/60000 (99.922%)\n",
      "Test set: average loss: 0.0003, accuracy: 9895/10000 (98.950%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 122 - Slope : 1.0\n",
      "Training Loss : 0.004174020141363144, training accuracy : 59926/60000 (99.877%)\n",
      "Test set: average loss: 0.0003, accuracy: 9897/10000 (98.970%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 123 - Slope : 1.0\n",
      "Training Loss : 0.003615115536376834, training accuracy : 59947/60000 (99.912%)\n",
      "Test set: average loss: 0.0003, accuracy: 9894/10000 (98.940%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 124 - Slope : 1.0\n",
      "Training Loss : 0.003632620209828019, training accuracy : 59930/60000 (99.883%)\n",
      "Test set: average loss: 0.0003, accuracy: 9884/10000 (98.840%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 125 - Slope : 1.0\n",
      "Training Loss : 0.0032775860745459795, training accuracy : 59948/60000 (99.913%)\n",
      "Test set: average loss: 0.0003, accuracy: 9881/10000 (98.810%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 126 - Slope : 1.0\n",
      "Training Loss : 0.003436563303694129, training accuracy : 59935/60000 (99.892%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 127 - Slope : 1.0\n",
      "Training Loss : 0.0036849172320216894, training accuracy : 59937/60000 (99.895%)\n",
      "Test set: average loss: 0.0003, accuracy: 9883/10000 (98.830%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 128 - Slope : 1.0\n",
      "Training Loss : 0.0030457363463938236, training accuracy : 59955/60000 (99.925%)\n",
      "Test set: average loss: 0.0003, accuracy: 9885/10000 (98.850%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 129 - Slope : 1.0\n",
      "Training Loss : 0.0036093846429139376, training accuracy : 59940/60000 (99.900%)\n",
      "Test set: average loss: 0.0003, accuracy: 9893/10000 (98.930%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 130 - Slope : 1.0\n",
      "Training Loss : 0.0032070151064544916, training accuracy : 59951/60000 (99.918%)\n",
      "Test set: average loss: 0.0003, accuracy: 9896/10000 (98.960%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 131 - Slope : 1.0\n",
      "Training Loss : 0.003306235186755657, training accuracy : 59950/60000 (99.917%)\n",
      "Test set: average loss: 0.0003, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 132 - Slope : 1.0\n",
      "Training Loss : 0.0033771954476833344, training accuracy : 59950/60000 (99.917%)\n",
      "Test set: average loss: 0.0003, accuracy: 9878/10000 (98.780%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 133 - Slope : 1.0\n",
      "Training Loss : 0.003327971091493964, training accuracy : 59942/60000 (99.903%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 134 - Slope : 1.0\n",
      "Training Loss : 0.0034524216316640377, training accuracy : 59944/60000 (99.907%)\n",
      "Test set: average loss: 0.0003, accuracy: 9897/10000 (98.970%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 135 - Slope : 1.0\n",
      "Training Loss : 0.0037822637241333723, training accuracy : 59927/60000 (99.878%)\n",
      "Test set: average loss: 0.0003, accuracy: 9898/10000 (98.980%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 136 - Slope : 1.0\n",
      "Training Loss : 0.003147084964439273, training accuracy : 59956/60000 (99.927%)\n",
      "Test set: average loss: 0.0003, accuracy: 9890/10000 (98.900%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 137 - Slope : 1.0\n",
      "Training Loss : 0.0031278261449187994, training accuracy : 59946/60000 (99.910%)\n",
      "Test set: average loss: 0.0003, accuracy: 9899/10000 (98.990%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 138 - Slope : 1.0\n",
      "Training Loss : 0.0028028974775224924, training accuracy : 59960/60000 (99.933%)\n",
      "Test set: average loss: 0.0003, accuracy: 9889/10000 (98.890%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 139 - Slope : 1.0\n",
      "Training Loss : 0.003164262743666768, training accuracy : 59947/60000 (99.912%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 140 - Slope : 1.0\n",
      "Training Loss : 0.003111459081992507, training accuracy : 59951/60000 (99.918%)\n",
      "Test set: average loss: 0.0003, accuracy: 9884/10000 (98.840%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 141 - Slope : 1.0\n",
      "Training Loss : 0.0028663999401032925, training accuracy : 59958/60000 (99.930%)\n",
      "Test set: average loss: 0.0003, accuracy: 9885/10000 (98.850%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 142 - Slope : 1.0\n",
      "Training Loss : 0.0028557516634464264, training accuracy : 59954/60000 (99.923%)\n",
      "Test set: average loss: 0.0003, accuracy: 9882/10000 (98.820%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 143 - Slope : 1.0\n",
      "Training Loss : 0.0027388527523726225, training accuracy : 59955/60000 (99.925%)\n",
      "Test set: average loss: 0.0003, accuracy: 9900/10000 (99.000%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 144 - Slope : 1.0\n",
      "Training Loss : 0.002488088561221957, training accuracy : 59963/60000 (99.938%)\n",
      "Test set: average loss: 0.0003, accuracy: 9884/10000 (98.840%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 145 - Slope : 1.0\n",
      "Training Loss : 0.0030164532363414764, training accuracy : 59949/60000 (99.915%)\n",
      "Test set: average loss: 0.0003, accuracy: 9900/10000 (99.000%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 146 - Slope : 1.0\n",
      "Training Loss : 0.003307604230940342, training accuracy : 59946/60000 (99.910%)\n",
      "Test set: average loss: 0.0003, accuracy: 9896/10000 (98.960%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 147 - Slope : 1.0\n",
      "Training Loss : 0.002470883773639798, training accuracy : 59967/60000 (99.945%)\n",
      "Test set: average loss: 0.0003, accuracy: 9881/10000 (98.810%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 148 - Slope : 1.0\n",
      "Training Loss : 0.002797826426103711, training accuracy : 59964/60000 (99.940%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 149 - Slope : 1.0\n",
      "Training Loss : 0.0026336079463362694, training accuracy : 59964/60000 (99.940%)\n",
      "Test set: average loss: 0.0003, accuracy: 9890/10000 (98.900%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 150 - Slope : 1.0\n",
      "Training Loss : 0.0027220856864005327, training accuracy : 59958/60000 (99.930%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 151 - Slope : 1.0\n",
      "Training Loss : 0.003013799199834466, training accuracy : 59952/60000 (99.920%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 152 - Slope : 1.0\n",
      "Training Loss : 0.002837463514879346, training accuracy : 59955/60000 (99.925%)\n",
      "Test set: average loss: 0.0003, accuracy: 9894/10000 (98.940%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 153 - Slope : 1.0\n",
      "Training Loss : 0.0029467938002198935, training accuracy : 59945/60000 (99.908%)\n",
      "Test set: average loss: 0.0003, accuracy: 9882/10000 (98.820%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 154 - Slope : 1.0\n",
      "Training Loss : 0.002704252954572439, training accuracy : 59956/60000 (99.927%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 155 - Slope : 1.0\n",
      "Training Loss : 0.002652388531714678, training accuracy : 59949/60000 (99.915%)\n",
      "Test set: average loss: 0.0003, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 156 - Slope : 1.0\n",
      "Training Loss : 0.0029485845007002354, training accuracy : 59947/60000 (99.912%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 157 - Slope : 1.0\n",
      "Training Loss : 0.00301826442591846, training accuracy : 59949/60000 (99.915%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 158 - Slope : 1.0\n",
      "Training Loss : 0.002266748109832406, training accuracy : 59974/60000 (99.957%)\n",
      "Test set: average loss: 0.0003, accuracy: 9889/10000 (98.890%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 159 - Slope : 1.0\n",
      "Training Loss : 0.002717050025239587, training accuracy : 59951/60000 (99.918%)\n",
      "Test set: average loss: 0.0003, accuracy: 9887/10000 (98.870%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 160 - Slope : 1.0\n",
      "Training Loss : 0.002589039970189333, training accuracy : 59956/60000 (99.927%)\n",
      "Test set: average loss: 0.0003, accuracy: 9900/10000 (99.000%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 161 - Slope : 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.0025284974835813046, training accuracy : 59961/60000 (99.935%)\n",
      "Test set: average loss: 0.0003, accuracy: 9893/10000 (98.930%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 162 - Slope : 1.0\n",
      "Training Loss : 0.0024670460261404514, training accuracy : 59967/60000 (99.945%)\n",
      "Test set: average loss: 0.0003, accuracy: 9893/10000 (98.930%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 163 - Slope : 1.0\n",
      "Training Loss : 0.002496326807886362, training accuracy : 59958/60000 (99.930%)\n",
      "Test set: average loss: 0.0003, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 164 - Slope : 1.0\n",
      "Training Loss : 0.0024232061114162207, training accuracy : 59964/60000 (99.940%)\n",
      "Test set: average loss: 0.0003, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 165 - Slope : 1.0\n",
      "Training Loss : 0.0025578374043107033, training accuracy : 59961/60000 (99.935%)\n",
      "Test set: average loss: 0.0003, accuracy: 9890/10000 (98.900%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 166 - Slope : 1.0\n",
      "Training Loss : 0.0022350193466991186, training accuracy : 59973/60000 (99.955%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 167 - Slope : 1.0\n",
      "Training Loss : 0.0024473012890666723, training accuracy : 59963/60000 (99.938%)\n",
      "Test set: average loss: 0.0003, accuracy: 9896/10000 (98.960%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 168 - Slope : 1.0\n",
      "Training Loss : 0.0023091305047273636, training accuracy : 59967/60000 (99.945%)\n",
      "Test set: average loss: 0.0003, accuracy: 9893/10000 (98.930%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 169 - Slope : 1.0\n",
      "Training Loss : 0.002352676820009947, training accuracy : 59968/60000 (99.947%)\n",
      "Test set: average loss: 0.0003, accuracy: 9897/10000 (98.970%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 170 - Slope : 1.0\n",
      "Training Loss : 0.0023415435571223497, training accuracy : 59963/60000 (99.938%)\n",
      "Test set: average loss: 0.0003, accuracy: 9881/10000 (98.810%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 171 - Slope : 1.0\n",
      "Training Loss : 0.002311853924766183, training accuracy : 59971/60000 (99.952%)\n",
      "Test set: average loss: 0.0003, accuracy: 9896/10000 (98.960%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 172 - Slope : 1.0\n",
      "Training Loss : 0.002047444460913539, training accuracy : 59970/60000 (99.950%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 173 - Slope : 1.0\n",
      "Training Loss : 0.0025109511334449053, training accuracy : 59962/60000 (99.937%)\n",
      "Test set: average loss: 0.0003, accuracy: 9883/10000 (98.830%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 174 - Slope : 1.0\n",
      "Training Loss : 0.0025085925590246916, training accuracy : 59961/60000 (99.935%)\n",
      "Test set: average loss: 0.0003, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 175 - Slope : 1.0\n",
      "Training Loss : 0.0023316482547670603, training accuracy : 59964/60000 (99.940%)\n",
      "Test set: average loss: 0.0003, accuracy: 9900/10000 (99.000%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 176 - Slope : 1.0\n",
      "Training Loss : 0.0022080796770751476, training accuracy : 59963/60000 (99.938%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 177 - Slope : 1.0\n",
      "Training Loss : 0.002303581451997161, training accuracy : 59962/60000 (99.937%)\n",
      "Test set: average loss: 0.0003, accuracy: 9899/10000 (98.990%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 178 - Slope : 1.0\n",
      "Training Loss : 0.002088867360725999, training accuracy : 59965/60000 (99.942%)\n",
      "Test set: average loss: 0.0003, accuracy: 9885/10000 (98.850%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 179 - Slope : 1.0\n",
      "Training Loss : 0.0019303907174617052, training accuracy : 59974/60000 (99.957%)\n",
      "Test set: average loss: 0.0003, accuracy: 9893/10000 (98.930%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 180 - Slope : 1.0\n",
      "Training Loss : 0.0022269561886787415, training accuracy : 59970/60000 (99.950%)\n",
      "Test set: average loss: 0.0003, accuracy: 9885/10000 (98.850%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 181 - Slope : 1.0\n",
      "Training Loss : 0.002016355749219656, training accuracy : 59978/60000 (99.963%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 182 - Slope : 1.0\n",
      "Training Loss : 0.002098405035212636, training accuracy : 59964/60000 (99.940%)\n",
      "Test set: average loss: 0.0003, accuracy: 9894/10000 (98.940%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 183 - Slope : 1.0\n",
      "Training Loss : 0.00212299358099699, training accuracy : 59968/60000 (99.947%)\n",
      "Test set: average loss: 0.0003, accuracy: 9889/10000 (98.890%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 184 - Slope : 1.0\n",
      "Training Loss : 0.0016769898356869817, training accuracy : 59981/60000 (99.968%)\n",
      "Test set: average loss: 0.0003, accuracy: 9901/10000 (99.010%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 185 - Slope : 1.0\n",
      "Training Loss : 0.0019911578856408596, training accuracy : 59981/60000 (99.968%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 186 - Slope : 1.0\n",
      "Training Loss : 0.0022446427028626204, training accuracy : 59972/60000 (99.953%)\n",
      "Test set: average loss: 0.0003, accuracy: 9884/10000 (98.840%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 187 - Slope : 1.0\n",
      "Training Loss : 0.002172013046219945, training accuracy : 59966/60000 (99.943%)\n",
      "Test set: average loss: 0.0003, accuracy: 9889/10000 (98.890%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 188 - Slope : 1.0\n",
      "Training Loss : 0.002008794341236353, training accuracy : 59969/60000 (99.948%)\n",
      "Test set: average loss: 0.0003, accuracy: 9887/10000 (98.870%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 189 - Slope : 1.0\n",
      "Training Loss : 0.0019542903173714876, training accuracy : 59973/60000 (99.955%)\n",
      "Test set: average loss: 0.0003, accuracy: 9897/10000 (98.970%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 190 - Slope : 1.0\n",
      "Training Loss : 0.0020901660900563, training accuracy : 59971/60000 (99.952%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 191 - Slope : 1.0\n",
      "Training Loss : 0.0019677148666232824, training accuracy : 59974/60000 (99.957%)\n",
      "Test set: average loss: 0.0003, accuracy: 9890/10000 (98.900%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 192 - Slope : 1.0\n",
      "Training Loss : 0.0019598326180130243, training accuracy : 59978/60000 (99.963%)\n",
      "Test set: average loss: 0.0003, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 193 - Slope : 1.0\n",
      "Training Loss : 0.0019212483894079924, training accuracy : 59979/60000 (99.965%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 194 - Slope : 1.0\n",
      "Training Loss : 0.0018290792359039187, training accuracy : 59978/60000 (99.963%)\n",
      "Test set: average loss: 0.0003, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 195 - Slope : 1.0\n",
      "Training Loss : 0.0020616166293621063, training accuracy : 59967/60000 (99.945%)\n",
      "Test set: average loss: 0.0003, accuracy: 9883/10000 (98.830%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 196 - Slope : 1.0\n",
      "Training Loss : 0.0019242254784330726, training accuracy : 59973/60000 (99.955%)\n",
      "Test set: average loss: 0.0003, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 197 - Slope : 1.0\n",
      "Training Loss : 0.002160279080271721, training accuracy : 59966/60000 (99.943%)\n",
      "Test set: average loss: 0.0003, accuracy: 9893/10000 (98.930%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 198 - Slope : 1.0\n",
      "Training Loss : 0.001890417537651956, training accuracy : 59976/60000 (99.960%)\n",
      "Test set: average loss: 0.0003, accuracy: 9901/10000 (99.010%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 199 - Slope : 1.0\n",
      "Training Loss : 0.001675962470471859, training accuracy : 59976/60000 (99.960%)\n",
      "Test set: average loss: 0.0003, accuracy: 9898/10000 (98.980%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 200 - Slope : 1.0\n",
      "Training Loss : 0.0016529213171452284, training accuracy : 59982/60000 (99.970%)\n",
      "Test set: average loss: 0.0003, accuracy: 9898/10000 (98.980%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 201 - Slope : 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.001637464971281588, training accuracy : 59975/60000 (99.958%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 202 - Slope : 1.0\n",
      "Training Loss : 0.0016346026677638292, training accuracy : 59978/60000 (99.963%)\n",
      "Test set: average loss: 0.0003, accuracy: 9889/10000 (98.890%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 203 - Slope : 1.0\n",
      "Training Loss : 0.002083742758259177, training accuracy : 59966/60000 (99.943%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 204 - Slope : 1.0\n",
      "Training Loss : 0.0016548236599192023, training accuracy : 59975/60000 (99.958%)\n",
      "Test set: average loss: 0.0003, accuracy: 9900/10000 (99.000%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 205 - Slope : 1.0\n",
      "Training Loss : 0.0019679677207022905, training accuracy : 59973/60000 (99.955%)\n",
      "Test set: average loss: 0.0003, accuracy: 9896/10000 (98.960%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 206 - Slope : 1.0\n",
      "Training Loss : 0.0020268463995307684, training accuracy : 59969/60000 (99.948%)\n",
      "Test set: average loss: 0.0004, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 207 - Slope : 1.0\n",
      "Training Loss : 0.0016558023635298014, training accuracy : 59980/60000 (99.967%)\n",
      "Test set: average loss: 0.0003, accuracy: 9900/10000 (99.000%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 208 - Slope : 1.0\n",
      "Training Loss : 0.0016410121461376548, training accuracy : 59979/60000 (99.965%)\n",
      "Test set: average loss: 0.0003, accuracy: 9896/10000 (98.960%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 209 - Slope : 1.0\n",
      "Training Loss : 0.0019271617056801915, training accuracy : 59976/60000 (99.960%)\n",
      "Test set: average loss: 0.0003, accuracy: 9880/10000 (98.800%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 210 - Slope : 1.0\n",
      "Training Loss : 0.0018949502846226096, training accuracy : 59969/60000 (99.948%)\n",
      "Test set: average loss: 0.0003, accuracy: 9899/10000 (98.990%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 211 - Slope : 1.0\n",
      "Training Loss : 0.0018212567083537579, training accuracy : 59967/60000 (99.945%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 212 - Slope : 1.0\n",
      "Training Loss : 0.0019211292965337634, training accuracy : 59972/60000 (99.953%)\n",
      "Test set: average loss: 0.0003, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 213 - Slope : 1.0\n",
      "Training Loss : 0.0018760766834020615, training accuracy : 59977/60000 (99.962%)\n",
      "Test set: average loss: 0.0003, accuracy: 9896/10000 (98.960%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 214 - Slope : 1.0\n",
      "Training Loss : 0.001865854486823082, training accuracy : 59969/60000 (99.948%)\n",
      "Test set: average loss: 0.0004, accuracy: 9882/10000 (98.820%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 215 - Slope : 1.0\n",
      "Training Loss : 0.0018988342490047216, training accuracy : 59973/60000 (99.955%)\n",
      "Test set: average loss: 0.0003, accuracy: 9889/10000 (98.890%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 216 - Slope : 1.0\n",
      "Training Loss : 0.0018446220783516765, training accuracy : 59971/60000 (99.952%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 217 - Slope : 1.0\n",
      "Training Loss : 0.0021293151658028364, training accuracy : 59966/60000 (99.943%)\n",
      "Test set: average loss: 0.0003, accuracy: 9897/10000 (98.970%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 218 - Slope : 1.0\n",
      "Training Loss : 0.0018317060312256217, training accuracy : 59974/60000 (99.957%)\n",
      "Test set: average loss: 0.0003, accuracy: 9898/10000 (98.980%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 219 - Slope : 1.0\n",
      "Training Loss : 0.0020211143419146538, training accuracy : 59963/60000 (99.938%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.040%\n",
      "# Epoch : 220 - Slope : 1.0\n",
      "Training Loss : 0.0019357884302735329, training accuracy : 59963/60000 (99.938%)\n",
      "Test set: average loss: 0.0003, accuracy: 9908/10000 (99.080%)\n",
      "Best test accuracy so far: 99.080%\n",
      "# Epoch : 221 - Slope : 1.0\n",
      "Training Loss : 0.001676315674558282, training accuracy : 59980/60000 (99.967%)\n",
      "Test set: average loss: 0.0003, accuracy: 9911/10000 (99.110%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 222 - Slope : 1.0\n",
      "Training Loss : 0.0018004262819886208, training accuracy : 59972/60000 (99.953%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 223 - Slope : 1.0\n",
      "Training Loss : 0.0017782337963581085, training accuracy : 59972/60000 (99.953%)\n",
      "Test set: average loss: 0.0003, accuracy: 9881/10000 (98.810%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 224 - Slope : 1.0\n",
      "Training Loss : 0.0017689339583739638, training accuracy : 59972/60000 (99.953%)\n",
      "Test set: average loss: 0.0003, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 225 - Slope : 1.0\n",
      "Training Loss : 0.0015288471477106214, training accuracy : 59981/60000 (99.968%)\n",
      "Test set: average loss: 0.0003, accuracy: 9898/10000 (98.980%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 226 - Slope : 1.0\n",
      "Training Loss : 0.0017389587592333555, training accuracy : 59974/60000 (99.957%)\n",
      "Test set: average loss: 0.0003, accuracy: 9890/10000 (98.900%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 227 - Slope : 1.0\n",
      "Training Loss : 0.001508797169663012, training accuracy : 59976/60000 (99.960%)\n",
      "Test set: average loss: 0.0003, accuracy: 9896/10000 (98.960%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 228 - Slope : 1.0\n",
      "Training Loss : 0.0015689892461523414, training accuracy : 59979/60000 (99.965%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 229 - Slope : 1.0\n",
      "Training Loss : 0.0017730551771819592, training accuracy : 59973/60000 (99.955%)\n",
      "Test set: average loss: 0.0003, accuracy: 9887/10000 (98.870%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 230 - Slope : 1.0\n",
      "Training Loss : 0.0014508288586512208, training accuracy : 59977/60000 (99.962%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 231 - Slope : 1.0\n",
      "Training Loss : 0.0016834483249112964, training accuracy : 59971/60000 (99.952%)\n",
      "Test set: average loss: 0.0003, accuracy: 9885/10000 (98.850%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 232 - Slope : 1.0\n",
      "Training Loss : 0.001341446884907782, training accuracy : 59986/60000 (99.977%)\n",
      "Test set: average loss: 0.0003, accuracy: 9893/10000 (98.930%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 233 - Slope : 1.0\n",
      "Training Loss : 0.0014298884198069572, training accuracy : 59981/60000 (99.968%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 234 - Slope : 1.0\n",
      "Training Loss : 0.0017264687921851873, training accuracy : 59975/60000 (99.958%)\n",
      "Test set: average loss: 0.0003, accuracy: 9894/10000 (98.940%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 235 - Slope : 1.0\n",
      "Training Loss : 0.0013597672805190086, training accuracy : 59985/60000 (99.975%)\n",
      "Test set: average loss: 0.0003, accuracy: 9896/10000 (98.960%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 236 - Slope : 1.0\n",
      "Training Loss : 0.0013825278729200363, training accuracy : 59985/60000 (99.975%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 237 - Slope : 1.0\n",
      "Training Loss : 0.0016201878897845745, training accuracy : 59979/60000 (99.965%)\n",
      "Test set: average loss: 0.0003, accuracy: 9889/10000 (98.890%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 238 - Slope : 1.0\n",
      "Training Loss : 0.0013670118059962988, training accuracy : 59985/60000 (99.975%)\n",
      "Test set: average loss: 0.0003, accuracy: 9890/10000 (98.900%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 239 - Slope : 1.0\n",
      "Training Loss : 0.0017736924346536398, training accuracy : 59968/60000 (99.947%)\n",
      "Test set: average loss: 0.0003, accuracy: 9882/10000 (98.820%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 240 - Slope : 1.0\n",
      "Training Loss : 0.0020349333062767982, training accuracy : 59968/60000 (99.947%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 241 - Slope : 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.0015258300118148327, training accuracy : 59981/60000 (99.968%)\n",
      "Test set: average loss: 0.0003, accuracy: 9878/10000 (98.780%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 242 - Slope : 1.0\n",
      "Training Loss : 0.0015887330519035459, training accuracy : 59978/60000 (99.963%)\n",
      "Test set: average loss: 0.0003, accuracy: 9896/10000 (98.960%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 243 - Slope : 1.0\n",
      "Training Loss : 0.0015082837780937552, training accuracy : 59984/60000 (99.973%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 244 - Slope : 1.0\n",
      "Training Loss : 0.0017640895675867796, training accuracy : 59973/60000 (99.955%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 245 - Slope : 1.0\n",
      "Training Loss : 0.0014024617848917842, training accuracy : 59978/60000 (99.963%)\n",
      "Test set: average loss: 0.0003, accuracy: 9890/10000 (98.900%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 246 - Slope : 1.0\n",
      "Training Loss : 0.0019077296601608396, training accuracy : 59974/60000 (99.957%)\n",
      "Test set: average loss: 0.0003, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 247 - Slope : 1.0\n",
      "Training Loss : 0.0015679888892918825, training accuracy : 59979/60000 (99.965%)\n",
      "Test set: average loss: 0.0003, accuracy: 9899/10000 (98.990%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 248 - Slope : 1.0\n",
      "Training Loss : 0.0015246450202539563, training accuracy : 59979/60000 (99.965%)\n",
      "Test set: average loss: 0.0003, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 249 - Slope : 1.0\n",
      "Training Loss : 0.0015933230752125382, training accuracy : 59981/60000 (99.968%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 250 - Slope : 1.0\n",
      "Training Loss : 0.001195346936583519, training accuracy : 59991/60000 (99.985%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 251 - Slope : 1.0\n",
      "Training Loss : 0.0016080597415566444, training accuracy : 59975/60000 (99.958%)\n",
      "Test set: average loss: 0.0003, accuracy: 9898/10000 (98.980%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 252 - Slope : 1.0\n",
      "Training Loss : 0.0015914980322122574, training accuracy : 59979/60000 (99.965%)\n",
      "Test set: average loss: 0.0003, accuracy: 9896/10000 (98.960%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 253 - Slope : 1.0\n",
      "Training Loss : 0.0015222947113215923, training accuracy : 59979/60000 (99.965%)\n",
      "Test set: average loss: 0.0003, accuracy: 9880/10000 (98.800%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 254 - Slope : 1.0\n",
      "Training Loss : 0.001424754154868424, training accuracy : 59980/60000 (99.967%)\n",
      "Test set: average loss: 0.0003, accuracy: 9882/10000 (98.820%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 255 - Slope : 1.0\n",
      "Training Loss : 0.0013564450200647116, training accuracy : 59982/60000 (99.970%)\n",
      "Test set: average loss: 0.0003, accuracy: 9887/10000 (98.870%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 256 - Slope : 1.0\n",
      "Training Loss : 0.001633103471249342, training accuracy : 59975/60000 (99.958%)\n",
      "Test set: average loss: 0.0003, accuracy: 9897/10000 (98.970%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 257 - Slope : 1.0\n",
      "Training Loss : 0.0012649608543142676, training accuracy : 59985/60000 (99.975%)\n",
      "Test set: average loss: 0.0003, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 258 - Slope : 1.0\n",
      "Training Loss : 0.0012431031791493297, training accuracy : 59985/60000 (99.975%)\n",
      "Test set: average loss: 0.0003, accuracy: 9889/10000 (98.890%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 259 - Slope : 1.0\n",
      "Training Loss : 0.001170171657577157, training accuracy : 59982/60000 (99.970%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 99.110%\n",
      "# Epoch : 260 - Slope : 1.0\n",
      "Training Loss : 0.0015967998187988997, training accuracy : 59975/60000 (99.958%)\n",
      "Test set: average loss: 0.0003, accuracy: 9912/10000 (99.120%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 261 - Slope : 1.0\n",
      "Training Loss : 0.0013712154468521476, training accuracy : 59983/60000 (99.972%)\n",
      "Test set: average loss: 0.0003, accuracy: 9887/10000 (98.870%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 262 - Slope : 1.0\n",
      "Training Loss : 0.0011793148005381227, training accuracy : 59990/60000 (99.983%)\n",
      "Test set: average loss: 0.0003, accuracy: 9896/10000 (98.960%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 263 - Slope : 1.0\n",
      "Training Loss : 0.0012911144876852632, training accuracy : 59988/60000 (99.980%)\n",
      "Test set: average loss: 0.0003, accuracy: 9891/10000 (98.910%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 264 - Slope : 1.0\n",
      "Training Loss : 0.001313959015533328, training accuracy : 59981/60000 (99.968%)\n",
      "Test set: average loss: 0.0003, accuracy: 9908/10000 (99.080%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 265 - Slope : 1.0\n",
      "Training Loss : 0.001185128465294838, training accuracy : 59984/60000 (99.973%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 266 - Slope : 1.0\n",
      "Training Loss : 0.0014515139628201723, training accuracy : 59973/60000 (99.955%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 267 - Slope : 1.0\n",
      "Training Loss : 0.0014168284833431244, training accuracy : 59981/60000 (99.968%)\n",
      "Test set: average loss: 0.0003, accuracy: 9890/10000 (98.900%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 268 - Slope : 1.0\n",
      "Training Loss : 0.0014641272136941552, training accuracy : 59979/60000 (99.965%)\n",
      "Test set: average loss: 0.0003, accuracy: 9894/10000 (98.940%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 269 - Slope : 1.0\n",
      "Training Loss : 0.00117426214274019, training accuracy : 59985/60000 (99.975%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 270 - Slope : 1.0\n",
      "Training Loss : 0.0014984242152422667, training accuracy : 59976/60000 (99.960%)\n",
      "Test set: average loss: 0.0003, accuracy: 9890/10000 (98.900%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 271 - Slope : 1.0\n",
      "Training Loss : 0.0013408763334155083, training accuracy : 59981/60000 (99.968%)\n",
      "Test set: average loss: 0.0003, accuracy: 9899/10000 (98.990%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 272 - Slope : 1.0\n",
      "Training Loss : 0.0014444187982007861, training accuracy : 59979/60000 (99.965%)\n",
      "Test set: average loss: 0.0003, accuracy: 9899/10000 (98.990%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 273 - Slope : 1.0\n",
      "Training Loss : 0.001322634518146515, training accuracy : 59983/60000 (99.972%)\n",
      "Test set: average loss: 0.0003, accuracy: 9886/10000 (98.860%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 274 - Slope : 1.0\n",
      "Training Loss : 0.0013271968346089125, training accuracy : 59980/60000 (99.967%)\n",
      "Test set: average loss: 0.0003, accuracy: 9901/10000 (99.010%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 275 - Slope : 1.0\n",
      "Training Loss : 0.0013009178219363093, training accuracy : 59980/60000 (99.967%)\n",
      "Test set: average loss: 0.0003, accuracy: 9894/10000 (98.940%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 276 - Slope : 1.0\n",
      "Training Loss : 0.0011296464363113046, training accuracy : 59986/60000 (99.977%)\n",
      "Test set: average loss: 0.0003, accuracy: 9898/10000 (98.980%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 277 - Slope : 1.0\n",
      "Training Loss : 0.0012556854635477066, training accuracy : 59984/60000 (99.973%)\n",
      "Test set: average loss: 0.0003, accuracy: 9898/10000 (98.980%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 278 - Slope : 1.0\n",
      "Training Loss : 0.0011068423045799136, training accuracy : 59990/60000 (99.983%)\n",
      "Test set: average loss: 0.0003, accuracy: 9893/10000 (98.930%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 279 - Slope : 1.0\n",
      "Training Loss : 0.0013991964515298605, training accuracy : 59977/60000 (99.962%)\n",
      "Test set: average loss: 0.0003, accuracy: 9894/10000 (98.940%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 280 - Slope : 1.0\n",
      "Training Loss : 0.0011428184807300568, training accuracy : 59991/60000 (99.985%)\n",
      "Test set: average loss: 0.0003, accuracy: 9888/10000 (98.880%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 281 - Slope : 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.0014063763665035367, training accuracy : 59975/60000 (99.958%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 282 - Slope : 1.0\n",
      "Training Loss : 0.0009800591506063938, training accuracy : 59991/60000 (99.985%)\n",
      "Test set: average loss: 0.0003, accuracy: 9876/10000 (98.760%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 283 - Slope : 1.0\n",
      "Training Loss : 0.0013640933902934194, training accuracy : 59979/60000 (99.965%)\n",
      "Test set: average loss: 0.0003, accuracy: 9901/10000 (99.010%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 284 - Slope : 1.0\n",
      "Training Loss : 0.0011993251973763108, training accuracy : 59983/60000 (99.972%)\n",
      "Test set: average loss: 0.0003, accuracy: 9895/10000 (98.950%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 285 - Slope : 1.0\n",
      "Training Loss : 0.0012198301265016198, training accuracy : 59984/60000 (99.973%)\n",
      "Test set: average loss: 0.0003, accuracy: 9885/10000 (98.850%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 286 - Slope : 1.0\n",
      "Training Loss : 0.0013329292414709926, training accuracy : 59982/60000 (99.970%)\n",
      "Test set: average loss: 0.0003, accuracy: 9895/10000 (98.950%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 287 - Slope : 1.0\n",
      "Training Loss : 0.001209737965837121, training accuracy : 59987/60000 (99.978%)\n",
      "Test set: average loss: 0.0003, accuracy: 9895/10000 (98.950%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 288 - Slope : 1.0\n",
      "Training Loss : 0.0010980581864714622, training accuracy : 59991/60000 (99.985%)\n",
      "Test set: average loss: 0.0003, accuracy: 9881/10000 (98.810%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 289 - Slope : 1.0\n",
      "Training Loss : 0.0011582402512431145, training accuracy : 59987/60000 (99.978%)\n",
      "Test set: average loss: 0.0003, accuracy: 9890/10000 (98.900%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 290 - Slope : 1.0\n",
      "Training Loss : 0.0010395300341770053, training accuracy : 59989/60000 (99.982%)\n",
      "Test set: average loss: 0.0003, accuracy: 9890/10000 (98.900%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 291 - Slope : 1.0\n",
      "Training Loss : 0.0013107159174978733, training accuracy : 59983/60000 (99.972%)\n",
      "Test set: average loss: 0.0003, accuracy: 9910/10000 (99.100%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 292 - Slope : 1.0\n",
      "Training Loss : 0.0014771543210372329, training accuracy : 59974/60000 (99.957%)\n",
      "Test set: average loss: 0.0003, accuracy: 9894/10000 (98.940%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 293 - Slope : 1.0\n",
      "Training Loss : 0.0013610285241156816, training accuracy : 59984/60000 (99.973%)\n",
      "Test set: average loss: 0.0003, accuracy: 9893/10000 (98.930%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 294 - Slope : 1.0\n",
      "Training Loss : 0.0010778732830658555, training accuracy : 59983/60000 (99.972%)\n",
      "Test set: average loss: 0.0003, accuracy: 9883/10000 (98.830%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 295 - Slope : 1.0\n",
      "Training Loss : 0.0012988924281671643, training accuracy : 59984/60000 (99.973%)\n",
      "Test set: average loss: 0.0003, accuracy: 9897/10000 (98.970%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 296 - Slope : 1.0\n",
      "Training Loss : 0.0012575439177453518, training accuracy : 59978/60000 (99.963%)\n",
      "Test set: average loss: 0.0003, accuracy: 9902/10000 (99.020%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 297 - Slope : 1.0\n",
      "Training Loss : 0.0012864532181993127, training accuracy : 59980/60000 (99.967%)\n",
      "Test set: average loss: 0.0003, accuracy: 9898/10000 (98.980%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 298 - Slope : 1.0\n",
      "Training Loss : 0.0013588869478553534, training accuracy : 59982/60000 (99.970%)\n",
      "Test set: average loss: 0.0003, accuracy: 9892/10000 (98.920%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 299 - Slope : 1.0\n",
      "Training Loss : 0.001057006185874343, training accuracy : 59989/60000 (99.982%)\n",
      "Test set: average loss: 0.0003, accuracy: 9896/10000 (98.960%)\n",
      "Best test accuracy so far: 99.120%\n",
      "# Epoch : 300 - Slope : 1.0\n",
      "Training Loss : 0.0009012771770358086, training accuracy : 59988/60000 (99.980%)\n",
      "Test set: average loss: 0.0003, accuracy: 9900/10000 (99.000%)\n",
      "Best test accuracy so far: 99.120%\n",
      "CPU times: user 50min, sys: 1min 22s, total: 51min 22s\n",
      "Wall time: 51min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "acc_track = []\n",
    "train_acc_track = []\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    train_loss, train_acc = train(epoch)\n",
    "    test_loss, test_acc = test(epoch, best_acc)\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    print(f'Best test accuracy so far: {best_acc*100:.3f}%')\n",
    "    acc_track.append(test_acc)\n",
    "    train_acc_track.append(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(miscPath / 'plot.mplstyle')\n",
    "\n",
    "fig, ax = plt.subplots(dpi=100)\n",
    "plt.plot(acc_track, label='Test accuracy')\n",
    "plt.plot(train_acc_track, label='Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f\"MNIST {image_size}x{image_size} best {best_acc*100:.4g}%\\n 784-C{n_chan}-{n_linear}-10\")\n",
    "plt.legend()\n",
    "plt.minorticks_on()\n",
    "plt.grid(which='both')\n",
    "plt.tight_layout()\n",
    "plt.savefig(plotPath / f'{model_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), modelPath / f'{model_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-qml_msy]",
   "language": "python",
   "name": "conda-env-.conda-qml_msy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
